{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad Demo: One-Shot LLM on Raw Data\n",
    "\n",
    "## ⚠️ WARNING: Anti-Pattern Demonstration\n",
    "\n",
    "**This notebook intentionally demonstrates the WRONG way to use LLMs for analytics.**\n",
    "\n",
    "We will:\n",
    "1. Show raw table schemas to an LLM with no semantic guidance\n",
    "2. Ask it to write SQL and provide insights in a single shot\n",
    "3. Watch it produce confident but completely wrong results\n",
    "\n",
    "### Expected Failure Modes\n",
    "\n",
    "This approach will fail in multiple ways:\n",
    "- **Revenue attribution error**: Wrong join path, attributing revenue incorrectly\n",
    "- **Many-to-many inflation**: Cartesian explosion from improper joins\n",
    "- **Time window drift**: Inconsistent date ranges across metrics\n",
    "- **Metric misuse**: Using orders instead of conversions in CAC calculation\n",
    "- **Dimension ambiguity**: Mixing utm_source and channel, causing duplication\n",
    "\n",
    "### Business Question\n",
    "\n",
    "\"Which channel mix change is most likely to improve CAC next month, given a recent anomaly in referral traffic?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment loaded\n",
      "✓ Database connected\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Connect to database\n",
    "db_path = '../data/synthetic_data.duckdb'\n",
    "conn = duckdb.connect(db_path, read_only=True)\n",
    "\n",
    "print(\"✓ Environment loaded\")\n",
    "print(\"✓ Database connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Raw Table Inventory\n",
    "\n",
    "Let's show the LLM our raw tables without any semantic guidance about:\n",
    "- How to join them safely\n",
    "- Which metrics are canonical\n",
    "- What time windows to use\n",
    "- How to attribute revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables:\n",
      "  - dim_adgroups\n",
      "  - dim_campaigns\n",
      "  - dim_creatives\n",
      "  - dim_customers\n",
      "  - dim_products\n",
      "  - fact_ad_spend\n",
      "  - fact_orders\n",
      "  - fact_sessions\n",
      "\n",
      "Database Schema:\n",
      "\n",
      "dim_adgroups:\n",
      "  - adgroup_id (VARCHAR)\n",
      "  - campaign_id (VARCHAR)\n",
      "  - audience (VARCHAR)\n",
      "  - placement (VARCHAR)\n",
      "\n",
      "dim_campaigns:\n",
      "  - campaign_id (VARCHAR)\n",
      "  - channel (VARCHAR)\n",
      "  - campaign_name (VARCHAR)\n",
      "  - start_date (DATE)\n",
      "  - end_date (DATE)\n",
      "  - objective (VARCHAR)\n",
      "\n",
      "dim_creatives:\n",
      "  - creative_id (VARCHAR)\n",
      "  - adgroup_id (VARCHAR)\n",
      "  - format (VARCHAR)\n",
      "  - asset_url (VARCHAR)\n",
      "\n",
      "dim_customers:\n",
      "  - customer_id (VARCHAR)\n",
      "  - first_visit_date (DATE)\n",
      "  - region (VARCHAR)\n",
      "  - loyalty_segment (VARCHAR)\n",
      "  - primary_device (VARCHAR)\n",
      "  - acquisition_channel (VARCHAR)\n",
      "\n",
      "dim_products:\n",
      "  - sku (VARCHAR)\n",
      "  - category (VARCHAR)\n",
      "  - subcategory (VARCHAR)\n",
      "  - brand (VARCHAR)\n",
      "  - price (DOUBLE)\n",
      "  - margin_pct (DOUBLE)\n",
      "  - margin (DOUBLE)\n",
      "\n",
      "fact_ad_spend:\n",
      "  - date (DATE)\n",
      "  - campaign_id (VA...\n"
     ]
    }
   ],
   "source": [
    "# Get table schemas\n",
    "tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
    "print(\"Available tables:\")\n",
    "for table in tables:\n",
    "    print(f\"  - {table[0]}\")\n",
    "\n",
    "# Build raw schema description for LLM\n",
    "schema_description = \"Database Schema:\\n\\n\"\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    columns = conn.execute(f\"DESCRIBE {table_name}\").fetchall()\n",
    "    schema_description += f\"{table_name}:\\n\"\n",
    "    for col in columns:\n",
    "        schema_description += f\"  - {col[0]} ({col[1]})\\n\"\n",
    "    schema_description += \"\\n\"\n",
    "\n",
    "# Show a preview\n",
    "print(\"\\n\" + schema_description[:800] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: One-Shot Prompt Execution\n",
    "\n",
    "Now we'll ask the LLM to write SQL to analyze the business question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "================================================================================\n",
      "To analyze the channel mix change that could improve Customer Acquisition Cost (CAC) next month, especially considering a recent anomaly in referral traffic, we will focus on the `fact_sessions` and `fact_orders` tables to determine the performance of each channel in terms of revenue generated and the number of customers acquired. We will also look at the total ad spend associated with each channel to calculate the CAC for each channel.\n",
      "\n",
      "Here’s the SQL query that accomplishes this:\n",
      "\n",
      "```sql\n",
      "WITH channel_performance AS (\n",
      "    SELECT \n",
      "        f.channel,\n",
      "        COUNT(DISTINCT f.customer_id) AS new_customers,\n",
      "        SUM(f.revenue) AS total_revenue,\n",
      "        SUM(f.spend) AS total_spend,\n",
      "        SUM(f.pages_viewed) AS total_pages_viewed\n",
      "    FROM \n",
      "        fact_sessions f\n",
      "    LEFT JOIN \n",
      "        fact_orders o ON f.session_id = o.session_id\n",
      "    WHERE \n",
      "        f.date >= CURRENT_DATE - INTERVAL '1 month' AND \n",
      "        f.date < CURRENT_DATE\n",
      "    GROUP BY \n",
      "        f.channel\n",
      "),\n",
      "cac_calculation AS (\n",
      "    SELECT \n",
      "        channel,\n",
      "        new_customers,\n",
      "        total_revenue,\n",
      "        total_spend,\n",
      "        CASE \n",
      "            WHEN new_customers > 0 THEN total_spend / new_customers \n",
      "            ELSE NULL \n",
      "        END AS cac\n",
      "    FROM \n",
      "        channel_performance\n",
      ")\n",
      "SELECT \n",
      "    channel,\n",
      "    cac,\n",
      "    total_revenue,\n",
      "    total_spend\n",
      "FROM \n",
      "    cac_calculation\n",
      "ORDER BY \n",
      "    cac ASC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "### Explanation of the Query:\n",
      "1. **CTE (Common Table Expression) `channel_performance`**: This aggregates data from the `fact_sessions` and `fact_orders` tables for the last month, calculating the number of new customers, total revenue, and total ad spend for each channel.\n",
      "\n",
      "2. **CTE `cac_calculation`**: Here, we calculate the CAC by dividing the total spend by the number of new customers for each channel. If there are no new customers for a channel (to avoid division by zero), it returns NULL.\n",
      "\n",
      "3. **Final Selection**: The final SELECT statement retrieves the channel with the minimum CAC, which indicates the most cost-effective channel for acquiring customers based on the previous month's data.\n",
      "\n",
      "By analyzing the output of this query, we can make recommendations for channel mix changes that are likely to improve the CAC next month.\n"
     ]
    }
   ],
   "source": [
    "business_question = \"\"\"Which channel mix change is most likely to improve CAC next month, \n",
    "given a recent anomaly in referral traffic?\"\"\"\n",
    "\n",
    "prompt = f\"\"\"{schema_description}\n",
    "\n",
    "Business Question: {business_question}\n",
    "\n",
    "You have just gotten a schema description for a set of tables in our warehouse with descriptive column names.\n",
    "\n",
    "Write a SINGLE SQL query to analyze this question and provide a recommendation.\n",
    "\n",
    "Return your response in this format:\n",
    "SQL:\n",
    "[your SQL query]\n",
    "\"\"\"\n",
    "\n",
    "# Call LLM\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "llm_output = response.choices[0].message.content\n",
    "print(\"LLM Response:\")\n",
    "print(\"=\" * 80)\n",
    "print(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse SQL from LLM response\n"
     ]
    }
   ],
   "source": [
    "# Extract and execute the SQL\n",
    "import re\n",
    "\n",
    "# Parse SQL from response\n",
    "sql_match = re.search(r'SQL:(.*?)(?:INSIGHT:|$)', llm_output, re.DOTALL)\n",
    "if sql_match:\n",
    "    generated_sql = sql_match.group(1).strip()\n",
    "    # Remove markdown code blocks if present\n",
    "    generated_sql = re.sub(r'^```sql\\s*', '', generated_sql)\n",
    "    generated_sql = re.sub(r'^```\\s*', '', generated_sql)\n",
    "    generated_sql = re.sub(r'```\\s*$', '', generated_sql)\n",
    "    generated_sql = generated_sql.strip()\n",
    "    \n",
    "    print(\"\\nExecuting generated SQL...\\n\")\n",
    "    print(generated_sql)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        result_df = conn.execute(generated_sql).df()\n",
    "        print(\"\\nQuery Results:\")\n",
    "        print(result_df)\n",
    "        \n",
    "        # Store for failure analysis\n",
    "        bad_results = result_df\n",
    "        bad_sql = generated_sql\n",
    "    except Exception as e:\n",
    "        print(f\"\\nQuery failed: {e}\")\n",
    "        bad_results = None\n",
    "        bad_sql = generated_sql\n",
    "else:\n",
    "    print(\"Could not parse SQL from LLM response\")\n",
    "    bad_results = None\n",
    "    bad_sql = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Failure Exhibit\n",
    "\n",
    "Let's analyze what went wrong with the LLM-generated SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:59:44.990243Z",
     "iopub.status.busy": "2025-11-09T14:59:44.990155Z",
     "iopub.status.idle": "2025-11-09T14:59:44.994544Z",
     "shell.execute_reply": "2025-11-09T14:59:44.994190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAILURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "1. Revenue Attribution Error\n",
      "   What happened: Joined fact_orders directly to dim_campaigns without going through fact_sessions\n",
      "   Impact: Revenue is incorrectly attributed; many orders will be dropped or duplicated\n",
      "   Correct approach: Must use: fact_orders → fact_sessions → dim_campaigns (last-touch attribution)\n",
      "\n",
      "2. Metric Definition Error\n",
      "   What happened: Used orders in CAC calculation instead of conversions\n",
      "   Impact: CAC is understated because not all sessions convert to orders\n",
      "   Correct approach: CAC = spend / conversions, where conversions come from fact_sessions.converted_flag\n"
     ]
    }
   ],
   "source": [
    "# Check for specific failure patterns\n",
    "failures = []\n",
    "\n",
    "if bad_sql:\n",
    "    sql_lower = bad_sql.lower()\n",
    "    \n",
    "    # Failure 1: Revenue attribution error\n",
    "    if 'fact_orders' in sql_lower and 'fact_sessions' not in sql_lower:\n",
    "        failures.append({\n",
    "            'failure': 'Revenue Attribution Error',\n",
    "            'description': 'Joined fact_orders directly to dim_campaigns without going through fact_sessions',\n",
    "            'impact': 'Revenue is incorrectly attributed; many orders will be dropped or duplicated',\n",
    "            'correct': 'Must use: fact_orders → fact_sessions → dim_campaigns (last-touch attribution)'\n",
    "        })\n",
    "    \n",
    "    # Failure 2: Many-to-many inflation\n",
    "    if 'fact_sessions' in sql_lower and 'fact_ad_spend' in sql_lower:\n",
    "        if sql_lower.count('join') >= 2 and 'session_id' not in sql_lower:\n",
    "            failures.append({\n",
    "                'failure': 'Many-to-Many Cartesian Explosion',\n",
    "                'description': 'Joined fact_sessions and fact_ad_spend on campaign_id without proper grain',\n",
    "                'impact': 'Row counts multiply incorrectly; metrics are inflated by 10-100x',\n",
    "                'correct': 'These tables must be aggregated separately before joining, or use semantic layer'\n",
    "            })\n",
    "    \n",
    "    # Failure 3: Time window drift\n",
    "    date_filters = re.findall(r'(date|timestamp).*?interval.*?(\\d+)', sql_lower)\n",
    "    if len(set([d[1] for d in date_filters])) > 1:\n",
    "        failures.append({\n",
    "            'failure': 'Time Window Drift',\n",
    "            'description': 'Different tables use different date ranges (e.g., 30 days for spend, 90 days for revenue)',\n",
    "            'impact': 'CAC calculation mixes mismatched time periods; results are meaningless',\n",
    "            'correct': 'All metrics must use the same canonical window (default: 90 days)'\n",
    "        })\n",
    "    \n",
    "    # Failure 4: Metric misuse\n",
    "    if 'order_id' in sql_lower and ('cac' in sql_lower or 'acquisition' in sql_lower):\n",
    "        failures.append({\n",
    "            'failure': 'Metric Definition Error',\n",
    "            'description': 'Used orders in CAC calculation instead of conversions',\n",
    "            'impact': 'CAC is understated because not all sessions convert to orders',\n",
    "            'correct': 'CAC = spend / conversions, where conversions come from fact_sessions.converted_flag'\n",
    "        })\n",
    "    \n",
    "    # Failure 5: Dimension ambiguity\n",
    "    if 'utm_source' in sql_lower or 'source' in sql_lower:\n",
    "        failures.append({\n",
    "            'failure': 'Dimension Ambiguity',\n",
    "            'description': 'Mixed dim_campaigns.channel with utm_source or other dimension',\n",
    "            'impact': 'Channels are inconsistently defined; totals don\\'t match',\n",
    "            'correct': 'Must use canonical dimension: dim_campaigns.channel only'\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FAILURE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, failure in enumerate(failures, 1):\n",
    "    print(f\"\\n{i}. {failure['failure']}\")\n",
    "    print(f\"   What happened: {failure['description']}\")\n",
    "    print(f\"   Impact: {failure['impact']}\")\n",
    "    print(f\"   Correct approach: {failure['correct']}\")\n",
    "\n",
    "if not failures:\n",
    "    print(\"\\nNo obvious failures detected in pattern matching, but the results are still likely wrong!\")\n",
    "    print(\"This demonstrates another problem: it's hard to even detect when one-shot LLM SQL fails.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: The Overconfident Narrative\n",
    "\n",
    "Despite these errors, the LLM produced a confident recommendation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:59:44.995949Z",
     "iopub.status.busy": "2025-11-09T14:59:44.995855Z",
     "iopub.status.idle": "2025-11-09T14:59:44.998031Z",
     "shell.execute_reply": "2025-11-09T14:59:44.997672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Recommendation:\n",
      "================================================================================\n",
      "To improve the Customer Acquisition Cost (CAC) next month, focus on channels with low CAC and high spend per order. Analyze the channels with the highest potential for optimization, particularly those showing anomalies in referral traffic, and consider reallocating budget from high CAC channels to those that demonstrate more efficient spending and higher order conversion rates.\n",
      "================================================================================\n",
      "\n",
      "⚠️ This recommendation is based on WRONG DATA due to the failures above.\n",
      "⚠️ Implementing this could waste budget and harm business performance.\n"
     ]
    }
   ],
   "source": [
    "# Extract insight\n",
    "insight_match = re.search(r'INSIGHT:(.*)', llm_output, re.DOTALL)\n",
    "if insight_match:\n",
    "    insight = insight_match.group(1).strip()\n",
    "    print(\"LLM Recommendation:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(insight)\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n⚠️ This recommendation is based on WRONG DATA due to the failures above.\")\n",
    "    print(\"⚠️ Implementing this could waste budget and harm business performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Post-Mortem Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "**Single LLM calls on raw data fail because:**\n",
    "\n",
    "1. **No semantic contracts**: The LLM doesn't know the canonical metric definitions\n",
    "2. **No join validation**: Complex schemas allow many wrong join paths\n",
    "3. **No time window enforcement**: Different metrics drift to different periods\n",
    "4. **No grain management**: Many-to-many joins cause silent data explosions\n",
    "5. **Overconfidence**: The LLM has no way to know it's wrong\n",
    "\n",
    "### The Right Way\n",
    "\n",
    "The solution requires:\n",
    "- **Semantic layer**: Canonical metrics with tested SQL templates\n",
    "- **Modular agents**: Small, focused, testable components\n",
    "- **Deterministic logic**: Use LLMs only for ambiguity resolution\n",
    "- **Observability**: Log every decision and SQL execution\n",
    "- **Testing**: Validate joins, grains, and results\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "See `02_good_modular_dspy.ipynb` for the correct implementation using:\n",
    "- DSPy agent architecture\n",
    "- Semantic layer from `config/semantic.yml`\n",
    "- Reproducible, testable, explainable analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T14:59:44.999281Z",
     "iopub.status.busy": "2025-11-09T14:59:44.999183Z",
     "iopub.status.idle": "2025-11-09T14:59:45.001913Z",
     "shell.execute_reply": "2025-11-09T14:59:45.001544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Demo complete. Database connection closed.\n",
      "\n",
      "Remember: This is what NOT to do. See the good demo for the right approach.\n"
     ]
    }
   ],
   "source": [
    "# Cleanup\n",
    "conn.close()\n",
    "print(\"\\n✓ Demo complete. Database connection closed.\")\n",
    "print(\"\\nRemember: This is what NOT to do. See the good demo for the right approach.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
