{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasman Agentic Analytics - Phase 1 Demo\n",
    "\n",
    "This notebook demonstrates the **local-first agentic analytics system** with minimal LLM usage.\n",
    "\n",
    "**Key Features:**\n",
    "- Rule-based triage (search vs analysis)\n",
    "- Template-based SQL generation\n",
    "- LLM fallback only when needed\n",
    "- Automatic visualization\n",
    "- Full observability of each step\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Validation\n",
    "\n",
    "Load configuration, connect to DuckDB, and validate schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Import our modules\n",
    "from core.duckdb_connector import DuckDBConnector\n",
    "from core.triage_local import LocalTriage\n",
    "from core.local_text_to_sql import LocalTextToSQL\n",
    "from core.llm_clients import LLMClient\n",
    "from agents.agent_triage import TriageAgent\n",
    "from agents.agent_text_to_sql import TextToSQLAgent\n",
    "from agents.agent_search import SearchAgent\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(PROJECT_ROOT / \".env\")\n",
    "    print(\"‚úÖ Environment loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è  No .env file or dotenv not available: {e}\")\n",
    "\n",
    "# Setup directories\n",
    "CONFIG_DIR = PROJECT_ROOT / \"config\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "CACHE_DIR = PROJECT_ROOT / \".cache\" / \"llm\"\n",
    "OUTPUT_DIR = Path.cwd() / \"outputs\"\n",
    "\n",
    "for d in (CACHE_DIR, OUTPUT_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Project root: {PROJECT_ROOT}\")\n",
    "print(f\"üìÅ Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration files\n",
    "def load_yaml(path: Path):\n",
    "    with open(path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "db_config = load_yaml(CONFIG_DIR / \"db.yaml\")\n",
    "business_context = load_yaml(CONFIG_DIR / \"business_context.yaml\")\n",
    "templates = load_yaml(CONFIG_DIR / \"sql_templates.yaml\")\n",
    "\n",
    "with open(CONFIG_DIR / \"schema.json\", 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   - {len(schema)} tables in schema\")\n",
    "print(f\"   - {len(templates)} SQL templates\")\n",
    "print(f\"   - {len(business_context['roles'])} roles configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DuckDB path and connect\n",
    "DUCKDB_PATH = Path(db_config['duckdb_path']).expanduser().resolve()\n",
    "DEFAULT_LIMIT = db_config.get('default_limit', 1000)\n",
    "\n",
    "print(f\"ü¶Ü DuckDB path: {DUCKDB_PATH}\")\n",
    "print(f\"üî¢ Default limit: {DEFAULT_LIMIT}\")\n",
    "\n",
    "# Check if DB exists\n",
    "if not DUCKDB_PATH.exists():\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: DuckDB file not found at {DUCKDB_PATH}\")\n",
    "    print(\"   You'll need to create this database before running queries.\")\n",
    "    print(\"   The notebook will continue but queries will fail.\")\n",
    "else:\n",
    "    print(\"‚úÖ DuckDB file exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database connector\n",
    "db_connector = DuckDBConnector(str(DUCKDB_PATH), default_limit=DEFAULT_LIMIT)\n",
    "\n",
    "try:\n",
    "    db_connector.connect()\n",
    "    print(\"‚úÖ Connected to DuckDB\")\n",
    "    \n",
    "    # List tables\n",
    "    tables = db_connector.list_tables()\n",
    "    print(f\"\\nüì¶ Tables in database ({len(tables)}):\")\n",
    "    for table in tables:\n",
    "        print(f\"   - {table}\")\n",
    "    \n",
    "    # Validate schema\n",
    "    is_valid, errors = db_connector.validate_schema(schema)\n",
    "    \n",
    "    if is_valid:\n",
    "        print(\"\\n‚úÖ Schema validation passed\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Schema validation failed:\")\n",
    "        for error in errors:\n",
    "            print(f\"   - {error}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database connection failed: {e}\")\n",
    "    print(\"   Notebook will continue but queries will fail.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure LLM (Optional)\n",
    "\n",
    "Set up LLM client for fallback. The system will work without LLM for known query patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LLM provider\n",
    "MODEL_PROVIDER = os.getenv(\"MODEL_PROVIDER\", \"openai\").lower()\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "ANTHROPIC_MODEL = os.getenv(\"ANTHROPIC_MODEL\", \"claude-3-5-haiku-20241022\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "print(f\"ü§ñ LLM Provider: {MODEL_PROVIDER}\")\n",
    "\n",
    "# Initialize LLM client (optional)\n",
    "llm_client = None\n",
    "\n",
    "try:\n",
    "    if MODEL_PROVIDER == \"openai\" and OPENAI_API_KEY:\n",
    "        llm_client = LLMClient(\n",
    "            provider=\"openai\",\n",
    "            cache_dir=CACHE_DIR,\n",
    "            temperature=0.2,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        print(f\"‚úÖ OpenAI client initialized (model: {OPENAI_MODEL})\")\n",
    "        \n",
    "    elif MODEL_PROVIDER == \"anthropic\" and ANTHROPIC_API_KEY:\n",
    "        llm_client = LLMClient(\n",
    "            provider=\"anthropic\",\n",
    "            cache_dir=CACHE_DIR,\n",
    "            temperature=0.2,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        print(f\"‚úÖ Anthropic client initialized (model: {ANTHROPIC_MODEL})\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è  No API key found - running in local-only mode\")\n",
    "        print(\"   Templates will handle known queries; unknown queries will fail gracefully.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  LLM initialization failed: {e}\")\n",
    "    print(\"   Continuing in local-only mode.\")\n",
    "    llm_client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Agents\n",
    "\n",
    "Set up triage, text-to-SQL, and search agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agents\n",
    "triage_agent = TriageAgent(\n",
    "    business_context=business_context,\n",
    "    llm_client=llm_client,\n",
    "    llm_threshold=0.6\n",
    ")\n",
    "\n",
    "text_to_sql_agent = TextToSQLAgent(\n",
    "    templates=templates,\n",
    "    schema=schema,\n",
    "    business_context=business_context,\n",
    "    llm_client=llm_client,\n",
    "    llm_threshold=0.6,\n",
    "    default_limit=DEFAULT_LIMIT\n",
    ")\n",
    "\n",
    "search_agent = SearchAgent(\n",
    "    triage_agent=triage_agent,\n",
    "    text_to_sql_agent=text_to_sql_agent,\n",
    "    db_connector=db_connector,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agents initialized\")\n",
    "print(\"   - TriageAgent: Rule-based + optional LLM fallback\")\n",
    "print(\"   - TextToSQLAgent: Template matching + optional LLM\")\n",
    "print(\"   - SearchAgent: End-to-end orchestration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Business Context & Templates\n",
    "\n",
    "Explore available roles, KPIs, and SQL templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available roles and their KPIs\n",
    "print(\"üë• Available Roles:\\n\")\n",
    "\n",
    "for role_name, role_config in business_context['roles'].items():\n",
    "    print(f\"**{role_name.upper()}**\")\n",
    "    print(f\"  KPIs: {', '.join(role_config['kpis'])}\")\n",
    "    print(f\"  Dimensions: {', '.join(role_config['dims'][:5])}...\")\n",
    "    print(f\"  Time window: {role_config['defaults']['time_window_days']} days\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available SQL templates\n",
    "print(\"üìã Available SQL Templates:\\n\")\n",
    "\n",
    "for i, template in enumerate(templates, 1):\n",
    "    print(f\"{i}. **{template['id']}**\")\n",
    "    print(f\"   Role: {template.get('role_hint', 'any')}\")\n",
    "    print(f\"   Example questions:\")\n",
    "    for utterance in template['utterances'][:2]:\n",
    "        print(f\"     - \\\"{utterance}\\\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ask Questions\n",
    "\n",
    "Now let's ask questions and see the system in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display results\n",
    "def display_result(result):\n",
    "    \"\"\"Display search result in a nice format.\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"QUESTION: {result['question']}\")\n",
    "    print(f\"ROLE: {result.get('role', 'auto-detected')}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Show steps\n",
    "    print(\"\\nüìã STEPS:\")\n",
    "    for step in result['steps']:\n",
    "        step_name = step['step'].replace('_', ' ').title()\n",
    "        used_llm = step.get('used_llm', False)\n",
    "        llm_indicator = \"ü§ñ (LLM)\" if used_llm else \"‚ö° (Local)\"\n",
    "        print(f\"  {step_name}: {llm_indicator}\")\n",
    "        if 'confidence' in step:\n",
    "            print(f\"    Confidence: {step['confidence']:.2f}\")\n",
    "        if 'method' in step:\n",
    "            print(f\"    Method: {step['method']}\")\n",
    "    \n",
    "    # Show status\n",
    "    status = result.get('status', 'unknown')\n",
    "    print(f\"\\nüìä STATUS: {status}\")\n",
    "    \n",
    "    if status != 'success':\n",
    "        print(f\"\\n‚ö†Ô∏è  {result.get('message', 'Unknown error')}\")\n",
    "        if 'errors' in result:\n",
    "            for error in result['errors']:\n",
    "                print(f\"   - {error}\")\n",
    "        return\n",
    "    \n",
    "    # Show SQL\n",
    "    if 'sql' in result:\n",
    "        print(\"\\nüíæ SQL QUERY:\")\n",
    "        print(\"```sql\")\n",
    "        print(result['sql'])\n",
    "        print(\"```\")\n",
    "    \n",
    "    # Show data preview\n",
    "    if 'data' in result and not result['data'].empty:\n",
    "        print(f\"\\nüìä RESULTS ({result['row_count']} rows):\")\n",
    "        display(result['data'].head(10))\n",
    "    \n",
    "    # Show visualization\n",
    "    if result.get('chart_path'):\n",
    "        print(f\"\\nüìà VISUALIZATION ({result['chart_type']}):\")\n",
    "        display(Image(filename=str(result['chart_path'])))\n",
    "    \n",
    "    # Show summary\n",
    "    if 'summary' in result:\n",
    "        print(f\"\\nüìù SUMMARY:\")\n",
    "        print(f\"   {result['summary']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Template-matched query (local, no LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should match a template and NOT call LLM\n",
    "result = search_agent.search(\n",
    "    question=\"show ad spend per channel over time\",\n",
    "    role=\"marketer\"\n",
    ")\n",
    "\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Another template-matched query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_agent.search(\n",
    "    question=\"which campaigns have the best click-through rate\",\n",
    "    role=\"marketer\"\n",
    ")\n",
    "\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: CEO perspective query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_agent.search(\n",
    "    question=\"revenue by product category\",\n",
    "    role=\"ceo\"\n",
    ")\n",
    "\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Novel query (may trigger LLM if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a novel query not in templates - will try LLM if available\n",
    "result = search_agent.search(\n",
    "    question=\"what are the top 10 products by revenue in the last 30 days?\",\n",
    "    role=\"cpo\"\n",
    ")\n",
    "\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Auto role detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No role specified - system will infer from question content\n",
    "result = search_agent.search(\n",
    "    question=\"conversion rate by device\"\n",
    ")\n",
    "\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Observability & Debugging\n",
    "\n",
    "Inspect the internal workings of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed view of triage result\n",
    "test_question = \"show me the top spending campaigns\"\n",
    "\n",
    "triage_result = triage_agent.triage(test_question, role=\"marketer\")\n",
    "print(\"üîç TRIAGE RESULT:\\n\")\n",
    "pprint(triage_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed view of SQL generation\n",
    "sql_result = text_to_sql_agent.generate_sql(test_question, role=\"marketer\")\n",
    "print(\"üîç SQL GENERATION RESULT:\\n\")\n",
    "pprint(sql_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Cells\n",
    "\n",
    "Quick smoke tests to ensure everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Schema validation\n",
    "print(\"TEST 1: Schema Validation\")\n",
    "is_valid, errors = db_connector.validate_schema(schema)\n",
    "assert is_valid, f\"Schema validation failed: {errors}\"\n",
    "print(\"‚úÖ PASSED\\n\")\n",
    "\n",
    "# Test 2: Template coverage\n",
    "print(\"TEST 2: Template Coverage\")\n",
    "test_questions = [\n",
    "    (\"spend by channel\", \"marketer\"),\n",
    "    (\"ctr by campaign\", \"marketer\"),\n",
    "    (\"orders by category\", \"ceo\"),\n",
    "]\n",
    "\n",
    "for question, role in test_questions:\n",
    "    result = text_to_sql_agent.generate_sql(question, role)\n",
    "    assert result['sql'] is not None, f\"Failed to generate SQL for: {question}\"\n",
    "    assert result['method'] == 'template_match', f\"Expected template match for: {question}\"\n",
    "    print(f\"  ‚úì {question}\")\n",
    "\n",
    "print(\"‚úÖ PASSED\\n\")\n",
    "\n",
    "# Test 3: Triage classification\n",
    "print(\"TEST 3: Triage Classification\")\n",
    "search_questions = [\"show me revenue\", \"how many orders\", \"plot spend by channel\"]\n",
    "analysis_questions = [\"why did revenue drop\", \"what drives conversion\", \"segment customers\"]\n",
    "\n",
    "for q in search_questions:\n",
    "    result = triage_agent.triage(q)\n",
    "    assert result['mode'] == 'search', f\"Expected 'search' for: {q}\"\n",
    "    print(f\"  ‚úì '{q}' ‚Üí search\")\n",
    "\n",
    "for q in analysis_questions:\n",
    "    result = triage_agent.triage(q)\n",
    "    assert result['mode'] == 'analysis', f\"Expected 'analysis' for: {q}\"\n",
    "    print(f\"  ‚úì '{q}' ‚Üí analysis\")\n",
    "\n",
    "print(\"‚úÖ PASSED\\n\")\n",
    "\n",
    "print(\"üéâ ALL TESTS PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Query Interface\n",
    "\n",
    "Try your own questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive query\n",
    "YOUR_QUESTION = \"show me conversion rate by device\"  # ‚Üê Change this!\n",
    "YOUR_ROLE = \"marketer\"  # ‚Üê Change this! Options: marketer, ceo, cpo, coo, or None for auto-detect\n",
    "\n",
    "result = search_agent.search(\n",
    "    question=YOUR_QUESTION,\n",
    "    role=YOUR_ROLE if YOUR_ROLE != \"None\" else None\n",
    ")\n",
    "\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cache Statistics\n",
    "\n",
    "Check LLM cache hits/misses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count cache files\n",
    "if CACHE_DIR.exists():\n",
    "    cache_files = list(CACHE_DIR.glob(\"*.json\"))\n",
    "    print(f\"üì¶ LLM Cache Statistics:\")\n",
    "    print(f\"   Total cached responses: {len(cache_files)}\")\n",
    "    print(f\"   Cache directory: {CACHE_DIR}\")\n",
    "    \n",
    "    if len(cache_files) > 0:\n",
    "        print(\"\\n   Recent cache entries:\")\n",
    "        for cache_file in sorted(cache_files, key=lambda f: f.stat().st_mtime, reverse=True)[:5]:\n",
    "            with open(cache_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                key_parts = data.get('key_parts', [])\n",
    "                if len(key_parts) > 2:\n",
    "                    print(f\"     - {key_parts[0]} call: {key_parts[-1][:50]}...\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No cache directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup\n",
    "\n",
    "Close database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "db_connector.close()\n",
    "print(\"‚úÖ Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
